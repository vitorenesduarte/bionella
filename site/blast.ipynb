{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de homologias por BLAST\n",
    "\n",
    "1. [blast.local_blastp(tag_to_files, db)](#local)\n",
    "2. [blast.docker_blastp(directory, db)](#docker)\n",
    "3. [blast.expasy_blastp(tag_to_files)](#expasy)\n",
    "4. [blast.blastp(tags_and_proteins, db, type)](#blast)\n",
    "5. [blast.write_queries_to_dir(tags_and_proteins, directory)](#write_queries_to_dir)\n",
    "6. [blast.extract_blast_info(tag_to_files, type)](#extract_blast_info)\n",
    "7. [add_info_to_blast_results(blast_results, uniprots)](#add_info_to_blast_results)\n",
    "8. [main()](#main)\n",
    "\n",
    "O objectivo desta fase era, dadas as proteínas que retirámos do ficheiro genbank, procurar sequências homólogas com a ferramenta BLAST. Esta fase foi iterada várias vezes à procura da melhor estratégia, e no final acabámos com várias alternativas para a execução do BLAST, que podem ser encontradas no módulo [`util.blast`](https://github.com/vitorenesduarte/bionella/blob/master/util/blast.py). As alternativas são:\n",
    "\n",
    "- __Local__\n",
    "- __Docker__\n",
    "- __ExPASy__\n",
    "\n",
    "Os resultados desta fase podem ser encontrados [aqui](blast_results.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"local\"></a>\n",
    "### Local\n",
    "\n",
    "Esta função assume que o BLAST está instalado localmente, e recebe como parâmetro a base de dados que deve usar. O primeiro argumento desta função, `tag_to_files`, é um dicionário no qual as chaves são os __locus_tag__ de cada gene, e os valores são pares em que a primeira componente é o ficheiro, onde se encontra a sequência de aminoácidos para ser usada na query, (__in_file__), e a segunda componente é o ficheiro onde deve ser guardado o resultado do BLAST (__out_file__).\n",
    "\n",
    "```python\n",
    "def local_blastp(tag_to_files, db):\n",
    "    \"\"\"\n",
    "    Corre o blast localmente.\n",
    "    \"\"\"\n",
    "\n",
    "    for tag in tag_to_files:\n",
    "        (in_file, out_file) = tag_to_files[tag]\n",
    "    \n",
    "        blastp_cline = NcbiblastpCommandline(\n",
    "            query=in_file,\n",
    "            db=db,\n",
    "            evalue=10,\n",
    "            outfmt=5,\n",
    "            out=out_file\n",
    "        )\n",
    "        blastp_cline()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"docker\"></a>\n",
    "### Docker\n",
    "\n",
    "Para evitar a instalação do BLAST, o download de bases de dados e a sua adição como base de dados a ser usada pelo BLAST, criámos uma imagem __Docker__ com a base de dados __UniProtKB - Swiss-Prot__ [retirada do site da UniProt](http://www.uniprot.org/downloads). Mais informação sobre esta imagem pode ser encontrada [aqui](docker.html).\n",
    "\n",
    "```python\n",
    "def docker_blastp(directory, db):\n",
    "    \"\"\"\n",
    "    Corre o blast numa instância docker.\n",
    "    \"\"\"\n",
    "    cmd = \"docker run -e QUERY_DIR=\" + directory \\\n",
    "                  + \" -e DB=\" + db \\\n",
    "                  + \" -v $PWD/\" + directory + \":/\" + directory \\\n",
    "                  + \" -ti vitorenesduarte/swissprot_blast\"\n",
    "\n",
    "    p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    p.wait()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"expasy\"></a>\n",
    "### ExPASy\n",
    "\n",
    "A terceira opção não corre o BLAST localmente, mas utiliza o serviço disponibilizado pelo site ExPASy.\n",
    "\n",
    "```python\n",
    "def expasy_blastp(tag_to_files):\n",
    "    \"\"\"\n",
    "    Corre o blast na expasy.\n",
    "    \"\"\"\n",
    "    for tag in tag_to_files:\n",
    "        (in_file, out_file) = tag_to_files[tag]\n",
    "        query = rw.read_file(in_file)\n",
    "        blast_result = www.expasy_blast(query)\n",
    "        rw.write_file(blast_result, out_file)\n",
    "```\n",
    "\n",
    "Esta função usa uma outra função definida no módulo [`util.www`](https://github.com/vitorenesduarte/bionella/blob/master/util/www.py) que corre o BLAST contra a base de dados __UniProtKB = Swiss-Prot + TrEMBL__, usando o serviço da ExPASy.\n",
    "\n",
    "```python\n",
    "def expasy_blast(query):\n",
    "    \"\"\"\n",
    "    Corre o blast na expasy.\n",
    "    \"\"\"\n",
    "\n",
    "    url = \"http://web.expasy.org/cgi-bin/blast/blast.pl\"\n",
    "    data = {\n",
    "        \"format\": \"xml\",\n",
    "        \"prot_db1\": \"UniProtKB\",\n",
    "        \"matrix\": \"BLOSUM62\",\n",
    "        \"showsc\": 50, # best scoring sequences\n",
    "        \"showal\": 50, # best alignments\n",
    "        \"seq\": query\n",
    "    }\n",
    "\n",
    "    response = requests.post(\n",
    "        url,\n",
    "        data=data\n",
    "    )\n",
    "\n",
    "    return response.text\n",
    "```\n",
    "\n",
    "Esta última opção permitiu-nos encontrar sequências com maior homologia do que as que estávamos a encontrar, utilizando apenas a __Swiss-Prot__ localmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"blast\"></a>\n",
    "### BLAST\n",
    "\n",
    "A função que engloba estas três opções recebe como argumento uma lista de pares em que a primeira componente é a __locus_tag__ da proteína, e a segunda componente é a respectiva sequência de aminoácidos. Recebe ainda qual o tipo de BLAST, __local__, __docker__ ou __expasy__, a utilizar.\n",
    "\n",
    "```python\n",
    "def blastp(tags_and_proteins, type=\"local\"):\n",
    "    \"\"\"\n",
    "    Corre o blast para a proteínas passadas como argumento.\n",
    "\n",
    "    O argumento type é opcional e pode ter dois valores:\n",
    "        - local\n",
    "        - docker\n",
    "        - expasy\n",
    "\n",
    "    É retornado um dicionário com os resultados.\n",
    "    \"\"\"\n",
    "\n",
    "    directory = \".query_dir\"\n",
    "    tag_to_files = write_queries_to_dir(tags_and_proteins, directory)\n",
    "\n",
    "    # correr o blast\n",
    "    if type == \"local\":\n",
    "        local_blastp(tag_to_files, \"swissprot\")\n",
    "    elif type == \"docker\":\n",
    "        docker_blastp(directory, \"swissprot\")\n",
    "    elif type == \"expasy\":\n",
    "        expasy_blastp(tag_to_files)\n",
    "    else:\n",
    "        raise Exception(\"Unsupported type: \" + type)\n",
    "\n",
    "    blast_results = extract_blast_info(tag_to_files, type)\n",
    "    return blast_results\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta função usa duas outras funções:\n",
    "\n",
    "<a name=\"write_queries_to_dir\"></a>\n",
    "- `write_queries_to_dir` que recebe uma lista de pares, __locus_tag__ e sequência de aminoácidos __protein__, e retorna um dicionário que mapeia __locus_tag__ para pares (__in_file__, __out_file__).\n",
    "\n",
    "```python\n",
    "def write_queries_to_dir(tags_and_proteins, directory):\n",
    "    \"\"\"\n",
    "    Grava as proteínas passadas como argumento na\n",
    "    diretoria também passada como argumento.\n",
    "    \"\"\"\n",
    "\n",
    "    tag_to_files = {}\n",
    "\n",
    "    # Apagar a diretoria e criar uma nova\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "    os.makedirs(directory)\n",
    "\n",
    "    for (tag, protein) in tags_and_proteins:\n",
    "        # Gravar a proteína num ficheiro\n",
    "        in_file = directory + \"/\" + fasta_it(tag)\n",
    "        rw.write_file(protein, in_file)\n",
    "\n",
    "        # registar esta informação num dicionário\n",
    "        out_file = directory + \"/\" + xml_it(fasta_it(tag))\n",
    "        tag_to_files[tag] = (in_file, out_file)\n",
    "\n",
    "    return tag_to_files\n",
    "```\n",
    "\n",
    "<a name=\"extract_blast_info\"></a>\n",
    "- `extract_blast_info` que dado este dicionário retorna um outro dicionário que mapeia __locus_tag__ para a lista de resultados do BLAST. Cada um destes resultados é um dicionário com:\n",
    "    - __uniprot_id__\n",
    "    - __evalue__\n",
    "    - __score__\n",
    "    - __identity__\n",
    "\n",
    "```python\n",
    "def extract_blast_info(tag_to_files, type):\n",
    "    \"\"\"\n",
    "    Extrai a informação que necessitamos dos resultados do blast.\n",
    "      - uniprot_id\n",
    "      - evalue\n",
    "      - score\n",
    "      - identity\n",
    "    \"\"\"\n",
    "\n",
    "    blast_results = {}\n",
    "\n",
    "    for tag in tag_to_files:\n",
    "        (_, out_file) = tag_to_files[tag]\n",
    "\n",
    "        ### Alguns resultados do blast, ao serem lidos de disco\n",
    "        ### na função rw.read_blast\n",
    "        ### estavam a dar erro ao fazer parsing nesta linha.\n",
    "        ### Como não necessitamos deste resultado,\n",
    "        ### optamos por removê-la.\n",
    "        regex = \".*Hsp_midline.*\"\n",
    "        rw.filter_file(regex, out_file)\n",
    "\n",
    "        handle = rw.read_blast(out_file)\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for a in handle.alignments:\n",
    "            # extrair o uniprot id\n",
    "            if type in [\"local\", \"docker\"]:\n",
    "                # nos blast locais, o uniprot_id está no hit_def\n",
    "                uniprot_id = a.hit_def.split(\"|\")[1]\n",
    "            elif type == \"expasy\":\n",
    "                # nos blast expasy, o uniprot_id está no hit_id\n",
    "                uniprot_id = a.hit_id.split(\"|\")[1]\n",
    "\n",
    "            # escolher sempre o primeiro hsp\n",
    "            hsp = a.hsps[0]\n",
    "            evalue = hsp.expect\n",
    "            score = hsp.score\n",
    "            identities = hsp.identities\n",
    "            align_length = hsp.align_length\n",
    "            identity = (identities * 100) / align_length\n",
    "\n",
    "            hit = {}\n",
    "            hit[\"uniprot_id\"] = uniprot_id\n",
    "            hit[\"evalue\"] = evalue\n",
    "            hit[\"score\"] = score\n",
    "            hit[\"identity\"] = identity\n",
    "            result.append(hit)\n",
    "\n",
    "        blast_results[tag] = result\n",
    "\n",
    "    return blast_results\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"add_info_to_blast_results\"></a>\n",
    "Nesta fase ainda precisávamos de mais informação para além daquela que é possível extrair dos resultados do BLAST, que foi conseguida utilizando um serviço do site UniProt descrito [aqui](uniprot_services.html).\n",
    "\n",
    "- __status__ (_reviewed_ ou _unreviewed_)\n",
    "- __organism__\n",
    "- __translation__ (sequência de aminoácidos)\n",
    "- __molecular_functions__ (_GO - Molecular functions_)\n",
    "\n",
    "Esta informação foi adicionada a cada um dos resultados provenientes do BLAST.\n",
    "\n",
    "```python\n",
    "def add_info_to_blast_results(blast_results, uniprots):\n",
    "    \"\"\"\n",
    "    Esta função adiciona aos blast results informação\n",
    "    retirada do site da uniprot.\n",
    "    \"\"\"\n",
    "\n",
    "    for tag in blast_results:\n",
    "        for i in range(len(blast_results[tag])):\n",
    "            uniprot_id = blast_results[tag][i][\"uniprot_id\"]\n",
    "\n",
    "            # esta proteína aparece nos resultados do blast como\n",
    "            # Q8TC84-2 mas a uniprot retorna a sua informação\n",
    "            # como Q8TC84\n",
    "            if uniprot_id == \"Q8TC84-2\":\n",
    "                uniprot_id = \"Q8TC84\"\n",
    "\n",
    "            properties = [\n",
    "                \"status\",\n",
    "                \"organism\",\n",
    "                \"translation\",\n",
    "                \"molecular_functions\"\n",
    "            ]\n",
    "\n",
    "            for p in properties:\n",
    "                value = uniprots[uniprot_id][p]\n",
    "                blast_results[tag][i][p] = value\n",
    "\n",
    "    return blast_results\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, automatizámos o processo de inferência da função, dados os resultados do BLAST. Uma função é considerada provável se aparecer em pelo menos 50% dos resultados do BLAST. Este inferência foi feita tanto para os 10 primeiros resultados como para os resultados todos.\n",
    "\n",
    "```python\n",
    "def infer_function(blast_results):\n",
    "    \"\"\"\n",
    "    Infere qual as funções mais prováveis tendo em consideração\n",
    "    os primeiros 10 resultados do blast,\n",
    "    e quais as funções mais prováveis tendo em consideração\n",
    "    todos os resultados do blast.\n",
    "    \"\"\"\n",
    "\n",
    "    all = {}\n",
    "\n",
    "    for tag in sorted(blast_results.keys()):\n",
    "        results = blast_results[tag]\n",
    "        # inferir função para os primeiros 10 resultados\n",
    "        inferred_top_ten = infer(results[0:10])\n",
    "        # inferir função para todos os resultados\n",
    "        inferred_all = infer(results)\n",
    "\n",
    "        all[tag] = {}\n",
    "        all[tag][\"top_ten\"] = inferred_top_ten\n",
    "        all[tag][\"all\"] = inferred_all\n",
    "\n",
    "    return all\n",
    "\n",
    "def infer(results):\n",
    "    \"\"\"\n",
    "    Esta função tenta inferir a função das proteínas baseando-se\n",
    "    numa lista de resultados do blast.\n",
    "    \"\"\"\n",
    "    inferred = []\n",
    "    leaderboard = defaultdict(int)\n",
    "\n",
    "    for result in results:\n",
    "        functions = result[\"molecular_functions\"]\n",
    "\n",
    "        # atualizar a leaderboard\n",
    "        for function in result[\"molecular_functions\"]:\n",
    "            leaderboard[function] += 1\n",
    "\n",
    "    # As funções que aparecem em pelo menos 50% dos resultados\n",
    "    # são consideradas potenciais funções\n",
    "    min = len(results) / 2\n",
    "\n",
    "    for function in leaderboard:\n",
    "        if leaderboard[function] >= min:\n",
    "            inferred.append(function)\n",
    "\n",
    "    return sorted(inferred)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"main\"></a>\n",
    "Todos estes passos podem ser encontrados no ficheiro [second.py](https://github.com/vitorenesduarte/bionella/tree/master/second.py) e resumem-se a:\n",
    "\n",
    "```python\n",
    "import util.rw as rw\n",
    "import util.blast as blast\n",
    "import util.www as www\n",
    "import util.util as util\n",
    "\n",
    "ncbi_json_path = \".ncbi.json\"\n",
    "blast_results_json_path = \".blast_results.json\"\n",
    "inferred_json_path = \".inferred.json\"\n",
    "\n",
    "dictionary = rw.read_json(ncbi_json_path)\n",
    "tags_and_proteins = util.get_tags_and_proteins(dictionary)\n",
    "\n",
    "blast_results = blast.blastp(\n",
    "    tags_and_proteins,\n",
    "    \"expasy\"\n",
    ")\n",
    "\n",
    "uniprot_ids = set()\n",
    "for tag in blast_results:\n",
    "    for result in blast_results[tag]:\n",
    "        uniprot_ids.add(result[\"uniprot_id\"])\n",
    "\n",
    "uniprot_ids = list(uniprot_ids)\n",
    "uniprots = www.fetch_uniprots(uniprot_ids)\n",
    "\n",
    "blast_results = add_info_to_blast_results(\n",
    "    blast_results,\n",
    "    uniprots\n",
    ")\n",
    "rw.write_json(blast_results, blast_results_json_path)\n",
    "\n",
    "inferred = infer_function(blast_results)\n",
    "rw.write_json(inferred, inferred_json_path)\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
